{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1693bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #importar herramientas del OS (acceso a archivos)\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import tensorflow as tf #Importar Framework de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2639717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib-inline\n",
    "#!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470432b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion estructura de carpetas\n",
    "#https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a57be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('workspace'),\n",
    "    'DATA_PATH' : os.path.join('workspace','data'),\n",
    "    'TRAINING_PATH' : os.path.join('workspace','training'),\n",
    "    'ANNOTATIONS_PATH' : os.path.join('workspace','data','annotations'),\n",
    "    'IMAGES_PATH' : os.path.join('workspace','data','images'),\n",
    "    'TRAIN_LABELS_PATH' : os.path.join('workspace','data','train_labels'),\n",
    "    'TEST_LABELS_PATH' : os.path.join('workspace','data','test_labels'),\n",
    "    'IMAGES_PATH' : os.path.join('workspace','data','images'),\n",
    "    'MODELS_PATH': os.path.join('Tensorflow','models'),\n",
    "}\n",
    "files = {\n",
    "    'ORIGINAL_MODEL_CONFIG':os.path.join('Tensorflow','models','research','object_detection','configs','tf2', MODEL_NAME+'.config'),\n",
    "    'MODEL_CONFIG':os.path.join('workspace','data', MODEL_NAME+'.config'),\n",
    "    'LABEL_MAP':os.path.join('workspace','data','label_map.pbtxt'),\n",
    "}\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir -p {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8ed2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘workspace/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ already there; not retrieving.\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "#Descargar modelo ssd seleccionado y descomprimirlo\n",
    "\n",
    "!wget -nc {MODEL_URL} -P {paths['DATA_PATH']}\n",
    "!tar -xzvf {os.path.join(paths['DATA_PATH'],MODEL_NAME+'.tar.gz')} --directory {paths['DATA_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f87fdf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Tensorflow/models' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "#Descargar modelos TF\n",
    "!git clone https://github.com/tensorflow/models.git {paths['MODELS_PATH']}\n",
    "!cp {files['ORIGINAL_MODEL_CONFIG']} {paths['DATA_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdbb242c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages)\u001b[0m\n",
      "Processing /home/jeronimo/Gits/myeyes-trainer/Tensorflow/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Requirement already satisfied: avro-python3 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (1.10.2)\n",
      "Requirement already satisfied: apache-beam in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (2.37.0)\n",
      "Requirement already satisfied: pillow in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (9.0.1)\n",
      "Requirement already satisfied: lxml in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (4.8.0)\n",
      "Requirement already satisfied: matplotlib in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (3.2.0)\n",
      "Requirement already satisfied: Cython in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (0.29.28)\n",
      "Requirement already satisfied: contextlib2 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (1.16.0)\n",
      "Requirement already satisfied: pycocotools in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (2.0.4)\n",
      "Requirement already satisfied: lvis in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (1.7.3)\n",
      "Requirement already satisfied: pandas in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (1.4.1)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (2.8.0)\n",
      "Requirement already satisfied: tensorflow_io in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (0.24.0)\n",
      "Requirement already satisfied: keras in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from object-detection==0.1) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-text~=2.8.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: seqeval in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.2)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: oauth2client in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.0)\n",
      "Requirement already satisfied: opencv-python-headless in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.5.64)\n",
      "Requirement already satisfied: tensorflow-addons in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.16.1)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: gin-config in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: tensorflow~=2.8.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.42.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: sacrebleu in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.2)\n",
      "Requirement already satisfied: sentencepiece in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.19.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.27.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.20.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: urllib3 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.25.11)\n",
      "Requirement already satisfied: tqdm in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.63.1)\n",
      "Requirement already satisfied: certifi in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
      "Requirement already satisfied: python-slugify in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2020.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from pandas->object-detection==0.1) (2022.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.24.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (58.0.4)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.4.10)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: orjson<4.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.6.7)\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.12.3)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.20.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: docopt in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from lvis->object-detection==0.1) (4.5.5.64)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from lvis->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from lvis->object-detection==0.1) (1.4.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: regex in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.3.15)\n",
      "Requirement already satisfied: colorama in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: portalocker in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: promise in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1657885 sha256=4cb0e9cc66d0db47c617f957f18f7f3629ed3b2a694e5e1105fd43cb99263276\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3lgcfbtn/wheels/0e/c2/c1/cfab67277d450ac4d5ef8c506f35d21b3c1e0587bd15cc276a\n",
      "Successfully built object-detection\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages)\u001b[0m\n",
      "Installing collected packages: object-detection\n",
      "  Attempting uninstall: object-detection\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -bject-detection (/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages)\u001b[0m\n",
      "Successfully installed object-detection-0.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bject-detection (/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt-get install protobuf-compiler\n",
    "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "482cbe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-26 15:18:30.692699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:18:30.737721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:18:30.738765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "Running tests under Python 3.9.7: /home/jeronimo/anaconda3/envs/tf_gpu/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-04-26 15:18:30.753686: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-26 15:18:30.755466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:18:30.755927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:18:30.756214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:18:31.687589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:18:31.688015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:18:31.688382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:18:31.688704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4304 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/object_detection/builders/model_builder.py:1102: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0426 15:18:31.965726 139688264151872 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.52s\n",
      "I0426 15:18:32.262198 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.52s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.51s\n",
      "I0426 15:18:32.778187 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.51s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n",
      "I0426 15:18:33.020665 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
      "I0426 15:18:33.238465 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.73s\n",
      "I0426 15:18:34.968792 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.73s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0426 15:18:34.974605 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0426 15:18:34.996529 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0426 15:18:35.011619 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I0426 15:18:35.027204 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "I0426 15:18:35.119317 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "I0426 15:18:35.204198 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "I0426 15:18:35.291021 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "I0426 15:18:35.378805 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
      "I0426 15:18:35.469392 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "I0426 15:18:35.497307 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0426 15:18:35.662205 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0426 15:18:35.662341 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0426 15:18:35.662419 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 3\n",
      "I0426 15:18:35.664512 139688264151872 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0426 15:18:35.688393 139688264151872 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0426 15:18:35.688502 139688264151872 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0426 15:18:35.758516 139688264151872 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0426 15:18:35.758620 139688264151872 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0426 15:18:35.925496 139688264151872 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0426 15:18:35.925602 139688264151872 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0426 15:18:36.096991 139688264151872 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0426 15:18:36.097097 139688264151872 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0426 15:18:36.339271 139688264151872 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0426 15:18:36.339376 139688264151872 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0426 15:18:36.583787 139688264151872 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0426 15:18:36.583896 139688264151872 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0426 15:18:36.935643 139688264151872 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0426 15:18:36.935755 139688264151872 efficientnet_model.py:144] round_filter input=320 output=320\n",
      "I0426 15:18:37.019202 139688264151872 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
      "I0426 15:18:37.058486 139688264151872 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0426 15:18:37.198547 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0426 15:18:37.198658 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0426 15:18:37.198716 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 4\n",
      "I0426 15:18:37.200135 139688264151872 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0426 15:18:37.216365 139688264151872 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0426 15:18:37.216471 139688264151872 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0426 15:18:37.346692 139688264151872 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0426 15:18:37.346795 139688264151872 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0426 15:18:37.573553 139688264151872 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0426 15:18:37.573659 139688264151872 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0426 15:18:37.798104 139688264151872 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0426 15:18:37.798212 139688264151872 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0426 15:18:38.097303 139688264151872 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0426 15:18:38.097412 139688264151872 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0426 15:18:38.392232 139688264151872 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0426 15:18:38.392340 139688264151872 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0426 15:18:38.761393 139688264151872 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0426 15:18:38.761504 139688264151872 efficientnet_model.py:144] round_filter input=320 output=320\n",
      "I0426 15:18:38.928210 139688264151872 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
      "I0426 15:18:38.957844 139688264151872 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0426 15:18:39.016465 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0426 15:18:39.016573 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0426 15:18:39.016650 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 5\n",
      "I0426 15:18:39.018053 139688264151872 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0426 15:18:39.033494 139688264151872 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0426 15:18:39.033589 139688264151872 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0426 15:18:39.152909 139688264151872 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0426 15:18:39.153010 139688264151872 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0426 15:18:39.374952 139688264151872 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0426 15:18:39.375063 139688264151872 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0426 15:18:39.606056 139688264151872 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0426 15:18:39.606160 139688264151872 efficientnet_model.py:144] round_filter input=80 output=88\n",
      "I0426 15:18:39.912852 139688264151872 efficientnet_model.py:144] round_filter input=80 output=88\n",
      "I0426 15:18:39.912959 139688264151872 efficientnet_model.py:144] round_filter input=112 output=120\n",
      "I0426 15:18:40.226696 139688264151872 efficientnet_model.py:144] round_filter input=112 output=120\n",
      "I0426 15:18:40.226804 139688264151872 efficientnet_model.py:144] round_filter input=192 output=208\n",
      "I0426 15:18:40.608819 139688264151872 efficientnet_model.py:144] round_filter input=192 output=208\n",
      "I0426 15:18:40.608925 139688264151872 efficientnet_model.py:144] round_filter input=320 output=352\n",
      "I0426 15:18:40.767272 139688264151872 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
      "I0426 15:18:40.800769 139688264151872 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0426 15:18:40.857161 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0426 15:18:40.857266 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0426 15:18:40.857321 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0426 15:18:40.858685 139688264151872 efficientnet_model.py:144] round_filter input=32 output=40\n",
      "I0426 15:18:40.875286 139688264151872 efficientnet_model.py:144] round_filter input=32 output=40\n",
      "I0426 15:18:40.875376 139688264151872 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0426 15:18:41.001232 139688264151872 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0426 15:18:41.001335 139688264151872 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0426 15:18:41.229274 139688264151872 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0426 15:18:41.229382 139688264151872 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0426 15:18:41.450238 139688264151872 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0426 15:18:41.450343 139688264151872 efficientnet_model.py:144] round_filter input=80 output=96\n",
      "I0426 15:18:41.935233 139688264151872 efficientnet_model.py:144] round_filter input=80 output=96\n",
      "I0426 15:18:41.935339 139688264151872 efficientnet_model.py:144] round_filter input=112 output=136\n",
      "I0426 15:18:42.332167 139688264151872 efficientnet_model.py:144] round_filter input=112 output=136\n",
      "I0426 15:18:42.332273 139688264151872 efficientnet_model.py:144] round_filter input=192 output=232\n",
      "I0426 15:18:42.794363 139688264151872 efficientnet_model.py:144] round_filter input=192 output=232\n",
      "I0426 15:18:42.794472 139688264151872 efficientnet_model.py:144] round_filter input=320 output=384\n",
      "I0426 15:18:42.959572 139688264151872 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
      "I0426 15:18:42.995116 139688264151872 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0426 15:18:43.060098 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0426 15:18:43.060208 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0426 15:18:43.060261 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0426 15:18:43.061668 139688264151872 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0426 15:18:43.079597 139688264151872 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0426 15:18:43.079698 139688264151872 efficientnet_model.py:144] round_filter input=16 output=24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0426 15:18:43.213943 139688264151872 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0426 15:18:43.214048 139688264151872 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0426 15:18:43.529120 139688264151872 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0426 15:18:43.529229 139688264151872 efficientnet_model.py:144] round_filter input=40 output=56\n",
      "I0426 15:18:43.831385 139688264151872 efficientnet_model.py:144] round_filter input=40 output=56\n",
      "I0426 15:18:43.831489 139688264151872 efficientnet_model.py:144] round_filter input=80 output=112\n",
      "I0426 15:18:44.279745 139688264151872 efficientnet_model.py:144] round_filter input=80 output=112\n",
      "I0426 15:18:44.279854 139688264151872 efficientnet_model.py:144] round_filter input=112 output=160\n",
      "I0426 15:18:44.741441 139688264151872 efficientnet_model.py:144] round_filter input=112 output=160\n",
      "I0426 15:18:44.741548 139688264151872 efficientnet_model.py:144] round_filter input=192 output=272\n",
      "I0426 15:18:45.359721 139688264151872 efficientnet_model.py:144] round_filter input=192 output=272\n",
      "I0426 15:18:45.359831 139688264151872 efficientnet_model.py:144] round_filter input=320 output=448\n",
      "I0426 15:18:45.516667 139688264151872 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
      "I0426 15:18:45.548069 139688264151872 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0426 15:18:45.618930 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0426 15:18:45.619044 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0426 15:18:45.619102 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0426 15:18:45.620453 139688264151872 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0426 15:18:45.635291 139688264151872 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0426 15:18:45.635371 139688264151872 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0426 15:18:45.807875 139688264151872 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0426 15:18:45.807992 139688264151872 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0426 15:18:46.167520 139688264151872 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0426 15:18:46.167625 139688264151872 efficientnet_model.py:144] round_filter input=40 output=64\n",
      "I0426 15:18:46.535497 139688264151872 efficientnet_model.py:144] round_filter input=40 output=64\n",
      "I0426 15:18:46.535600 139688264151872 efficientnet_model.py:144] round_filter input=80 output=128\n",
      "I0426 15:18:47.170321 139688264151872 efficientnet_model.py:144] round_filter input=80 output=128\n",
      "I0426 15:18:47.170427 139688264151872 efficientnet_model.py:144] round_filter input=112 output=176\n",
      "I0426 15:18:47.708653 139688264151872 efficientnet_model.py:144] round_filter input=112 output=176\n",
      "I0426 15:18:47.708759 139688264151872 efficientnet_model.py:144] round_filter input=192 output=304\n",
      "I0426 15:18:48.371338 139688264151872 efficientnet_model.py:144] round_filter input=192 output=304\n",
      "I0426 15:18:48.371443 139688264151872 efficientnet_model.py:144] round_filter input=320 output=512\n",
      "I0426 15:18:48.599845 139688264151872 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
      "I0426 15:18:48.631084 139688264151872 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0426 15:18:48.713932 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0426 15:18:48.714048 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0426 15:18:48.714101 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0426 15:18:48.715421 139688264151872 efficientnet_model.py:144] round_filter input=32 output=56\n",
      "I0426 15:18:48.731569 139688264151872 efficientnet_model.py:144] round_filter input=32 output=56\n",
      "I0426 15:18:48.731654 139688264151872 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0426 15:18:48.910402 139688264151872 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0426 15:18:48.910503 139688264151872 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0426 15:18:49.341442 139688264151872 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0426 15:18:49.341545 139688264151872 efficientnet_model.py:144] round_filter input=40 output=72\n",
      "I0426 15:18:49.784595 139688264151872 efficientnet_model.py:144] round_filter input=40 output=72\n",
      "I0426 15:18:49.784699 139688264151872 efficientnet_model.py:144] round_filter input=80 output=144\n",
      "I0426 15:18:50.373190 139688264151872 efficientnet_model.py:144] round_filter input=80 output=144\n",
      "I0426 15:18:50.373298 139688264151872 efficientnet_model.py:144] round_filter input=112 output=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0426 15:18:50.965100 139688264151872 efficientnet_model.py:144] round_filter input=112 output=200\n",
      "I0426 15:18:50.965204 139688264151872 efficientnet_model.py:144] round_filter input=192 output=344\n",
      "I0426 15:18:51.768195 139688264151872 efficientnet_model.py:144] round_filter input=192 output=344\n",
      "I0426 15:18:51.768297 139688264151872 efficientnet_model.py:144] round_filter input=320 output=576\n",
      "I0426 15:18:51.995483 139688264151872 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
      "I0426 15:18:52.025330 139688264151872 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0426 15:18:52.245106 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0426 15:18:52.245217 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0426 15:18:52.245274 139688264151872 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0426 15:18:52.246706 139688264151872 efficientnet_model.py:144] round_filter input=32 output=64\n",
      "I0426 15:18:52.265205 139688264151872 efficientnet_model.py:144] round_filter input=32 output=64\n",
      "I0426 15:18:52.265308 139688264151872 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0426 15:18:52.529029 139688264151872 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0426 15:18:52.529137 139688264151872 efficientnet_model.py:144] round_filter input=24 output=48\n",
      "I0426 15:18:53.066591 139688264151872 efficientnet_model.py:144] round_filter input=24 output=48\n",
      "I0426 15:18:53.066698 139688264151872 efficientnet_model.py:144] round_filter input=40 output=80\n",
      "I0426 15:18:53.591591 139688264151872 efficientnet_model.py:144] round_filter input=40 output=80\n",
      "I0426 15:18:53.591695 139688264151872 efficientnet_model.py:144] round_filter input=80 output=160\n",
      "I0426 15:18:54.356336 139688264151872 efficientnet_model.py:144] round_filter input=80 output=160\n",
      "I0426 15:18:54.356449 139688264151872 efficientnet_model.py:144] round_filter input=112 output=224\n",
      "I0426 15:18:55.106176 139688264151872 efficientnet_model.py:144] round_filter input=112 output=224\n",
      "I0426 15:18:55.106296 139688264151872 efficientnet_model.py:144] round_filter input=192 output=384\n",
      "I0426 15:18:56.085030 139688264151872 efficientnet_model.py:144] round_filter input=192 output=384\n",
      "I0426 15:18:56.085136 139688264151872 efficientnet_model.py:144] round_filter input=320 output=640\n",
      "I0426 15:18:56.386415 139688264151872 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
      "I0426 15:18:56.418299 139688264151872 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.03s\n",
      "I0426 15:18:56.532709 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
      "I0426 15:18:56.624888 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0426 15:18:56.626175 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0426 15:18:56.626521 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0426 15:18:56.627712 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0426 15:18:56.628789 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0426 15:18:56.629081 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0426 15:18:56.629904 139688264151872 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 25.883s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "#Evaluador de requisitos [Tiene que decir OK al final]\n",
    "VERIFICATION_SCRIPT = os.path.join(paths['MODELS_PATH'],'research','object_detection','builders','model_builder_tf2_test.py')\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa54687",
   "metadata": {},
   "source": [
    "# DESDE ESTE PUNTO ES NECESARIO QUE LAS IMAGENES Y SUS LABELS XML SE ENCUENTREN COLOCADAS EN LA CARPETA IMAGES Y ANNOTATIONS RESPECTIVAMENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0bbec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ELIMINA TODAS LAS LABELS DE TRAIN Y TESTING\n",
    "for f in os.listdir(paths['TRAIN_LABELS_PATH']):\n",
    "    os.remove(os.path.join(paths['TRAIN_LABELS_PATH'], f))\n",
    "for f in os.listdir(paths['TEST_LABELS_PATH']):\n",
    "    os.remove(os.path.join(paths['TEST_LABELS_PATH'], f))\n",
    "\n",
    "#GENERA UNA LISTA DE TODAS LAS LABES EN ANNOTATIONS Y LAS DIVIDE EN 0.8\n",
    "allFileNames = os.listdir(paths['ANNOTATIONS_PATH'])\n",
    "np.random.shuffle(allFileNames)\n",
    "train_FileNames, test_FileNames =  np.split(np.array(allFileNames),[int(len(allFileNames)*0.8)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56b5fcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenes de entrenamiento: 20\n",
      "Imagenes de prueba: 5\n"
     ]
    }
   ],
   "source": [
    "print(f'Imagenes de entrenamiento: {len(train_FileNames)}')\n",
    "print(f'Imagenes de prueba: {len(test_FileNames)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a75efae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUARDA LAS LABES EN tran_labels Y test_labels\n",
    "train_FileNames = [paths['ANNOTATIONS_PATH']+'/'+ name for name in train_FileNames.tolist()]\n",
    "test_FileNames = [paths['ANNOTATIONS_PATH']+'/' + name for name in test_FileNames.tolist()]\n",
    "for name in train_FileNames:\n",
    "    shutil.copy(name, paths['TRAIN_LABELS_PATH'])\n",
    "for name in test_FileNames:\n",
    "    shutil.copy(name, paths['TEST_LABELS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57678d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted train_labels xml to csv.\n",
      "Successfully converted test_labels xml to csv.\n"
     ]
    }
   ],
   "source": [
    "#GENERA label_map.pbtxt y train y test csv\n",
    "\n",
    "#Tomado de https://github.com/techzizou/Train-Object-Detection-Model-TF-2.x y modificado\n",
    "#Se debe asegurar que en test_labels se encuentre por lo menos 1 de cada tipo de xml\n",
    "def xml_to_csv(path):\n",
    "  classes_names = []\n",
    "  xml_list = []\n",
    "\n",
    "  for xml_file in glob.glob(path + '/*.xml'):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    for member in root.findall('object'):\n",
    "      classes_names.append(member[0].text)\n",
    "      value = (root.find('filename').text  ,       \n",
    "               int(root.find('size')[0].text),\n",
    "               int(root.find('size')[1].text),\n",
    "               member[0].text,\n",
    "               int(member[4][0].text),\n",
    "               int(member[4][1].text),\n",
    "               int(member[4][2].text),\n",
    "               int(member[4][3].text))\n",
    "      xml_list.append(value)\n",
    "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
    "  classes_names = list(set(classes_names))\n",
    "  classes_names.sort()\n",
    "  return xml_df, classes_names\n",
    "\n",
    "for label_path in ['train_labels', 'test_labels']:\n",
    "  image_path = os.path.join(paths['DATA_PATH'], label_path)\n",
    "  xml_df, classes = xml_to_csv(image_path)\n",
    "  xml_df.to_csv(f'{image_path}.csv', index=None)\n",
    "  print(f'Successfully converted {label_path} xml to csv.')\n",
    "\n",
    "label_map_path = os.path.join(paths['DATA_PATH'],\"label_map.pbtxt\")\n",
    "labelmap_path = os.path.join(paths['DATA_PATH'],\"labelmap.txt\")\n",
    "\n",
    "pbtxt_content = \"\"\n",
    "txt_content = \"\"\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    pbtxt_content = (\n",
    "        pbtxt_content\n",
    "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n",
    "    )\n",
    "    txt_content = (\n",
    "        txt_content\n",
    "        + \"{0}\\n\".format(class_name)\n",
    "    )\n",
    "pbtxt_content = pbtxt_content.strip()\n",
    "txt_content = txt_content.strip()\n",
    "with open(label_map_path, \"w\") as f:\n",
    "    f.write(pbtxt_content)\n",
    "with open(labelmap_path, \"w\") as f:\n",
    "    f.write(txt_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53870b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups: 100%|██████████████████████████████████| 20/20 [00:00<00:00, 230.39it/s]\n",
      "Successfully created the TFRecords: /home/jeronimo/Gits/myeyes-trainer/workspace/data/train.record\n",
      "groups: 100%|████████████████████████████████████| 5/5 [00:00<00:00, 104.50it/s]\n",
      "Successfully created the TFRecords: /home/jeronimo/Gits/myeyes-trainer/workspace/data/test.record\n"
     ]
    }
   ],
   "source": [
    "#Tomado de https://github.com/techzizou/Train-Object-Detection-Model-TF-2.x\n",
    "\n",
    "!python generate_tfrecord.py {os.path.join(paths['DATA_PATH'],'train_labels.csv')} {os.path.join(paths['DATA_PATH'],'label_map.pbtxt')} {paths['IMAGES_PATH']} {os.path.join(paths['DATA_PATH'],'train.record')}\n",
    "!python generate_tfrecord.py {os.path.join(paths['DATA_PATH'],'test_labels.csv')} {os.path.join(paths['DATA_PATH'],'label_map.pbtxt')} {paths['IMAGES_PATH']} {os.path.join(paths['DATA_PATH'],'test.record')}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a3597",
   "metadata": {},
   "source": [
    "## Editar Configuracion Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac51b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a905145",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['MODEL_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c845bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 2\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 4\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"/home/jeronimo/Gits/myeyes-trainer/workspace/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"detection\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"/home/jeronimo/Gits/myeyes-trainer/workspace/data/label_map.pbtxt\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"/home/jeronimo/Gits/myeyes-trainer/workspace/data/train.record\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"/home/jeronimo/Gits/myeyes-trainer/workspace/data/label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"/home/jeronimo/Gits/myeyes-trainer/workspace/data/test.record\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"/home/jeronimo/Gits/myeyes-trainer/workspace/data/label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"/home/jeronimo/Gits/myeyes-trainer/workspace/data/test.record\"\n",
       " }}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5f56ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['MODEL_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1467c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(classes)\n",
    "pipeline_config.train_config.batch_size = 4 #PROBAR CON 8 \n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.abspath(os.path.join(paths['DATA_PATH'], MODEL_NAME, 'checkpoint', 'ckpt-0'))\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= os.path.abspath(files['LABEL_MAP'])\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.abspath(os.path.join(paths['DATA_PATH'], 'train.record'))]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = os.path.abspath(files['LABEL_MAP'])\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.abspath(os.path.join(paths['DATA_PATH'], 'test.record'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaabf7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['MODEL_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64b98ed",
   "metadata": {},
   "source": [
    "# Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c369ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nota:\n",
    "#En caso de cambiar de modelo, borrar contenidos de workspace/training\n",
    "shutil.rmtree(paths['TRAINING_PATH'])\n",
    "!mkdir -p {paths['TRAINING_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7e93a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --model_dir={} --alsologtostderr  --num_train_steps=2000\".format(os.path.join(paths['MODELS_PATH'],'research','object_detection','model_main_tf2.py' ),files['MODEL_CONFIG'],paths['TRAINING_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92024f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python Tensorflow/models/research/object_detection/model_main_tf2.py --pipeline_config_path=workspace/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=workspace/training --alsologtostderr  --num_train_steps=2000'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0c533fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.10.0-dev20220421). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n",
      "2022-04-26 15:20:11.247732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:20:11.252067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:20:11.252372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:20:11.252905: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-26 15:20:11.253432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:20:11.253699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:20:11.253948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:20:11.629836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:20:11.630147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:20:11.630397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:20:11.630620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4051 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0426 15:20:11.690183 140640455746496 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
      "I0426 15:20:11.692897 140640455746496 config_util.py:552] Maybe overwriting train_steps: 2000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0426 15:20:11.692969 140640455746496 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0426 15:20:11.712743 140640455746496 deprecation.py:350] From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/home/jeronimo/Gits/myeyes-trainer/workspace/data/train.record']\n",
      "I0426 15:20:11.717798 140640455746496 dataset_builder.py:162] Reading unweighted datasets: ['/home/jeronimo/Gits/myeyes-trainer/workspace/data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/home/jeronimo/Gits/myeyes-trainer/workspace/data/train.record']\n",
      "I0426 15:20:11.717916 140640455746496 dataset_builder.py:79] Reading record datasets for input file: ['/home/jeronimo/Gits/myeyes-trainer/workspace/data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0426 15:20:11.717966 140640455746496 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0426 15:20:11.718007 140640455746496 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0426 15:20:11.722400 140640455746496 deprecation.py:350] From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0426 15:20:11.734230 140640455746496 deprecation.py:350] From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0426 15:20:16.584681 140640455746496 deprecation.py:350] From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0426 15:20:18.662788 140640455746496 deprecation.py:350] From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0426 15:20:19.803560 140640455746496 deprecation.py:350] From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2022-04-26 15:20:38.331188: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.829714 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.831403 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.834803 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.835427 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.839803 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.840356 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.844908 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.845465 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.848940 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0426 15:20:41.849684 140640455746496 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0426 15:20:42.532569 140634836936448 deprecation.py:554] From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 100 per-step time 0.427s\n",
      "I0426 15:21:24.860183 140640455746496 model_lib_v2.py:705] Step 100 per-step time 0.427s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.381054,\n",
      " 'Loss/localization_loss': 0.33296105,\n",
      " 'Loss/regularization_loss': 0.15452261,\n",
      " 'Loss/total_loss': 0.86853766,\n",
      " 'learning_rate': 0.0319994}\n",
      "I0426 15:21:24.860641 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.381054,\n",
      " 'Loss/localization_loss': 0.33296105,\n",
      " 'Loss/regularization_loss': 0.15452261,\n",
      " 'Loss/total_loss': 0.86853766,\n",
      " 'learning_rate': 0.0319994}\n",
      "INFO:tensorflow:Step 200 per-step time 0.178s\n",
      "I0426 15:21:42.575509 140640455746496 model_lib_v2.py:705] Step 200 per-step time 0.178s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2555492,\n",
      " 'Loss/localization_loss': 0.4063324,\n",
      " 'Loss/regularization_loss': 0.15486737,\n",
      " 'Loss/total_loss': 0.8167489,\n",
      " 'learning_rate': 0.0373328}\n",
      "I0426 15:21:42.576480 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.2555492,\n",
      " 'Loss/localization_loss': 0.4063324,\n",
      " 'Loss/regularization_loss': 0.15486737,\n",
      " 'Loss/total_loss': 0.8167489,\n",
      " 'learning_rate': 0.0373328}\n",
      "INFO:tensorflow:Step 300 per-step time 0.208s\n",
      "I0426 15:22:03.335495 140640455746496 model_lib_v2.py:705] Step 300 per-step time 0.208s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30872262,\n",
      " 'Loss/localization_loss': 0.19443719,\n",
      " 'Loss/regularization_loss': 0.15481749,\n",
      " 'Loss/total_loss': 0.65797734,\n",
      " 'learning_rate': 0.0426662}\n",
      "I0426 15:22:03.336638 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.30872262,\n",
      " 'Loss/localization_loss': 0.19443719,\n",
      " 'Loss/regularization_loss': 0.15481749,\n",
      " 'Loss/total_loss': 0.65797734,\n",
      " 'learning_rate': 0.0426662}\n",
      "INFO:tensorflow:Step 400 per-step time 0.223s\n",
      "I0426 15:22:25.612224 140640455746496 model_lib_v2.py:705] Step 400 per-step time 0.223s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.141043,\n",
      " 'Loss/localization_loss': 0.07659284,\n",
      " 'Loss/regularization_loss': 0.15456548,\n",
      " 'Loss/total_loss': 0.37220132,\n",
      " 'learning_rate': 0.047999598}\n",
      "I0426 15:22:25.612658 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.141043,\n",
      " 'Loss/localization_loss': 0.07659284,\n",
      " 'Loss/regularization_loss': 0.15456548,\n",
      " 'Loss/total_loss': 0.37220132,\n",
      " 'learning_rate': 0.047999598}\n",
      "INFO:tensorflow:Step 500 per-step time 0.196s\n",
      "I0426 15:22:45.284874 140640455746496 model_lib_v2.py:705] Step 500 per-step time 0.196s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11565416,\n",
      " 'Loss/localization_loss': 0.11324302,\n",
      " 'Loss/regularization_loss': 0.15424898,\n",
      " 'Loss/total_loss': 0.38314617,\n",
      " 'learning_rate': 0.053333}\n",
      "I0426 15:22:45.285353 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.11565416,\n",
      " 'Loss/localization_loss': 0.11324302,\n",
      " 'Loss/regularization_loss': 0.15424898,\n",
      " 'Loss/total_loss': 0.38314617,\n",
      " 'learning_rate': 0.053333}\n",
      "INFO:tensorflow:Step 600 per-step time 0.216s\n",
      "I0426 15:23:06.829667 140640455746496 model_lib_v2.py:705] Step 600 per-step time 0.216s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09648877,\n",
      " 'Loss/localization_loss': 0.12461733,\n",
      " 'Loss/regularization_loss': 0.15389313,\n",
      " 'Loss/total_loss': 0.37499923,\n",
      " 'learning_rate': 0.0586664}\n",
      "I0426 15:23:06.830113 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.09648877,\n",
      " 'Loss/localization_loss': 0.12461733,\n",
      " 'Loss/regularization_loss': 0.15389313,\n",
      " 'Loss/total_loss': 0.37499923,\n",
      " 'learning_rate': 0.0586664}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 700 per-step time 0.202s\n",
      "I0426 15:23:26.993618 140640455746496 model_lib_v2.py:705] Step 700 per-step time 0.202s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13026215,\n",
      " 'Loss/localization_loss': 0.05677515,\n",
      " 'Loss/regularization_loss': 0.15350091,\n",
      " 'Loss/total_loss': 0.3405382,\n",
      " 'learning_rate': 0.0639998}\n",
      "I0426 15:23:26.994480 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.13026215,\n",
      " 'Loss/localization_loss': 0.05677515,\n",
      " 'Loss/regularization_loss': 0.15350091,\n",
      " 'Loss/total_loss': 0.3405382,\n",
      " 'learning_rate': 0.0639998}\n",
      "INFO:tensorflow:Step 800 per-step time 0.213s\n",
      "I0426 15:23:48.293614 140640455746496 model_lib_v2.py:705] Step 800 per-step time 0.213s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11479043,\n",
      " 'Loss/localization_loss': 0.08169305,\n",
      " 'Loss/regularization_loss': 0.15303296,\n",
      " 'Loss/total_loss': 0.34951645,\n",
      " 'learning_rate': 0.069333196}\n",
      "I0426 15:23:48.294701 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.11479043,\n",
      " 'Loss/localization_loss': 0.08169305,\n",
      " 'Loss/regularization_loss': 0.15303296,\n",
      " 'Loss/total_loss': 0.34951645,\n",
      " 'learning_rate': 0.069333196}\n",
      "INFO:tensorflow:Step 900 per-step time 0.216s\n",
      "I0426 15:24:09.864175 140640455746496 model_lib_v2.py:705] Step 900 per-step time 0.216s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.122026555,\n",
      " 'Loss/localization_loss': 0.06308295,\n",
      " 'Loss/regularization_loss': 0.1525239,\n",
      " 'Loss/total_loss': 0.3376334,\n",
      " 'learning_rate': 0.074666604}\n",
      "I0426 15:24:09.865226 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.122026555,\n",
      " 'Loss/localization_loss': 0.06308295,\n",
      " 'Loss/regularization_loss': 0.1525239,\n",
      " 'Loss/total_loss': 0.3376334,\n",
      " 'learning_rate': 0.074666604}\n",
      "INFO:tensorflow:Step 1000 per-step time 0.226s\n",
      "I0426 15:24:32.450712 140640455746496 model_lib_v2.py:705] Step 1000 per-step time 0.226s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10206098,\n",
      " 'Loss/localization_loss': 0.026581166,\n",
      " 'Loss/regularization_loss': 0.15188733,\n",
      " 'Loss/total_loss': 0.28052947,\n",
      " 'learning_rate': 0.08}\n",
      "I0426 15:24:32.451050 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.10206098,\n",
      " 'Loss/localization_loss': 0.026581166,\n",
      " 'Loss/regularization_loss': 0.15188733,\n",
      " 'Loss/total_loss': 0.28052947,\n",
      " 'learning_rate': 0.08}\n",
      "INFO:tensorflow:Step 1100 per-step time 0.236s\n",
      "I0426 15:24:56.055641 140640455746496 model_lib_v2.py:705] Step 1100 per-step time 0.236s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0767726,\n",
      " 'Loss/localization_loss': 0.042587113,\n",
      " 'Loss/regularization_loss': 0.1511936,\n",
      " 'Loss/total_loss': 0.27055332,\n",
      " 'learning_rate': 0.07999918}\n",
      "I0426 15:24:56.056206 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.0767726,\n",
      " 'Loss/localization_loss': 0.042587113,\n",
      " 'Loss/regularization_loss': 0.1511936,\n",
      " 'Loss/total_loss': 0.27055332,\n",
      " 'learning_rate': 0.07999918}\n",
      "INFO:tensorflow:Step 1200 per-step time 0.225s\n",
      "I0426 15:25:18.520597 140640455746496 model_lib_v2.py:705] Step 1200 per-step time 0.225s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.102443285,\n",
      " 'Loss/localization_loss': 0.036268346,\n",
      " 'Loss/regularization_loss': 0.15052459,\n",
      " 'Loss/total_loss': 0.28923622,\n",
      " 'learning_rate': 0.079996705}\n",
      "I0426 15:25:18.521106 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.102443285,\n",
      " 'Loss/localization_loss': 0.036268346,\n",
      " 'Loss/regularization_loss': 0.15052459,\n",
      " 'Loss/total_loss': 0.28923622,\n",
      " 'learning_rate': 0.079996705}\n",
      "INFO:tensorflow:Step 1300 per-step time 0.224s\n",
      "I0426 15:25:40.883474 140640455746496 model_lib_v2.py:705] Step 1300 per-step time 0.224s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07470988,\n",
      " 'Loss/localization_loss': 0.027971312,\n",
      " 'Loss/regularization_loss': 0.14982054,\n",
      " 'Loss/total_loss': 0.25250173,\n",
      " 'learning_rate': 0.0799926}\n",
      "I0426 15:25:40.884086 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.07470988,\n",
      " 'Loss/localization_loss': 0.027971312,\n",
      " 'Loss/regularization_loss': 0.14982054,\n",
      " 'Loss/total_loss': 0.25250173,\n",
      " 'learning_rate': 0.0799926}\n",
      "INFO:tensorflow:Step 1400 per-step time 0.230s\n",
      "I0426 15:26:03.843826 140640455746496 model_lib_v2.py:705] Step 1400 per-step time 0.230s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.05219313,\n",
      " 'Loss/localization_loss': 0.024813117,\n",
      " 'Loss/regularization_loss': 0.14907141,\n",
      " 'Loss/total_loss': 0.22607766,\n",
      " 'learning_rate': 0.07998685}\n",
      "I0426 15:26:03.844999 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.05219313,\n",
      " 'Loss/localization_loss': 0.024813117,\n",
      " 'Loss/regularization_loss': 0.14907141,\n",
      " 'Loss/total_loss': 0.22607766,\n",
      " 'learning_rate': 0.07998685}\n",
      "INFO:tensorflow:Step 1500 per-step time 0.234s\n",
      "I0426 15:26:27.204817 140640455746496 model_lib_v2.py:705] Step 1500 per-step time 0.234s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.048721015,\n",
      " 'Loss/localization_loss': 0.025220636,\n",
      " 'Loss/regularization_loss': 0.1483804,\n",
      " 'Loss/total_loss': 0.22232205,\n",
      " 'learning_rate': 0.07997945}\n",
      "I0426 15:26:27.205148 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.048721015,\n",
      " 'Loss/localization_loss': 0.025220636,\n",
      " 'Loss/regularization_loss': 0.1483804,\n",
      " 'Loss/total_loss': 0.22232205,\n",
      " 'learning_rate': 0.07997945}\n",
      "INFO:tensorflow:Step 1600 per-step time 0.247s\n",
      "I0426 15:26:51.944209 140640455746496 model_lib_v2.py:705] Step 1600 per-step time 0.247s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06275166,\n",
      " 'Loss/localization_loss': 0.015618353,\n",
      " 'Loss/regularization_loss': 0.14767222,\n",
      " 'Loss/total_loss': 0.22604224,\n",
      " 'learning_rate': 0.079970405}\n",
      "I0426 15:26:51.945291 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.06275166,\n",
      " 'Loss/localization_loss': 0.015618353,\n",
      " 'Loss/regularization_loss': 0.14767222,\n",
      " 'Loss/total_loss': 0.22604224,\n",
      " 'learning_rate': 0.079970405}\n",
      "INFO:tensorflow:Step 1700 per-step time 0.261s\n",
      "I0426 15:27:18.000497 140640455746496 model_lib_v2.py:705] Step 1700 per-step time 0.261s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.055023883,\n",
      " 'Loss/localization_loss': 0.028641986,\n",
      " 'Loss/regularization_loss': 0.14692938,\n",
      " 'Loss/total_loss': 0.23059526,\n",
      " 'learning_rate': 0.07995972}\n",
      "I0426 15:27:18.001747 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.055023883,\n",
      " 'Loss/localization_loss': 0.028641986,\n",
      " 'Loss/regularization_loss': 0.14692938,\n",
      " 'Loss/total_loss': 0.23059526,\n",
      " 'learning_rate': 0.07995972}\n",
      "INFO:tensorflow:Step 1800 per-step time 0.233s\n",
      "I0426 15:27:41.245486 140640455746496 model_lib_v2.py:705] Step 1800 per-step time 0.233s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08074913,\n",
      " 'Loss/localization_loss': 0.026116585,\n",
      " 'Loss/regularization_loss': 0.14618479,\n",
      " 'Loss/total_loss': 0.2530505,\n",
      " 'learning_rate': 0.0799474}\n",
      "I0426 15:27:41.246489 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.08074913,\n",
      " 'Loss/localization_loss': 0.026116585,\n",
      " 'Loss/regularization_loss': 0.14618479,\n",
      " 'Loss/total_loss': 0.2530505,\n",
      " 'learning_rate': 0.0799474}\n",
      "INFO:tensorflow:Step 1900 per-step time 0.212s\n",
      "I0426 15:28:02.510479 140640455746496 model_lib_v2.py:705] Step 1900 per-step time 0.212s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.049347434,\n",
      " 'Loss/localization_loss': 0.040961593,\n",
      " 'Loss/regularization_loss': 0.1454717,\n",
      " 'Loss/total_loss': 0.23578073,\n",
      " 'learning_rate': 0.07993342}\n",
      "I0426 15:28:02.511883 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.049347434,\n",
      " 'Loss/localization_loss': 0.040961593,\n",
      " 'Loss/regularization_loss': 0.1454717,\n",
      " 'Loss/total_loss': 0.23578073,\n",
      " 'learning_rate': 0.07993342}\n",
      "INFO:tensorflow:Step 2000 per-step time 0.213s\n",
      "I0426 15:28:23.816410 140640455746496 model_lib_v2.py:705] Step 2000 per-step time 0.213s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.05864117,\n",
      " 'Loss/localization_loss': 0.031856563,\n",
      " 'Loss/regularization_loss': 0.1447122,\n",
      " 'Loss/total_loss': 0.23520993,\n",
      " 'learning_rate': 0.07991781}\n",
      "I0426 15:28:23.816933 140640455746496 model_lib_v2.py:708] {'Loss/classification_loss': 0.05864117,\n",
      " 'Loss/localization_loss': 0.031856563,\n",
      " 'Loss/regularization_loss': 0.1447122,\n",
      " 'Loss/total_loss': 0.23520993,\n",
      " 'learning_rate': 0.07991781}\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea16197",
   "metadata": {},
   "source": [
    "# Evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ece15414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bde520f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {}  --trained_checkpoint_dir={} --pipeline_config_path={} --output_directory {}\".format(os.path.join(paths['MODELS_PATH'],'research','object_detection','exporter_main_v2.py'),paths['TRAINING_PATH'],files['MODEL_CONFIG'],os.path.join(paths['DATA_PATH'],'inference_graph'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a2d056d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python Tensorflow/models/research/object_detection/exporter_main_v2.py  --trained_checkpoint_dir=workspace/training --pipeline_config_path=workspace/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --output_directory workspace/data/inference_graph'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "064b7180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-26 15:28:31.918516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:28:31.929486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:28:31.929810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:28:31.934096: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-26 15:28:31.934688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:28:31.935048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:28:31.935349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:28:32.414572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:28:32.414942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:28:32.415256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:28:32.415528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:tensorflow:From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0426 15:28:32.672831 140405113897920 deprecation.py:623] From /home/jeronimo/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb2382886d0>, because it is not built.\n",
      "W0426 15:28:49.749302 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb2382886d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb238221670>, because it is not built.\n",
      "W0426 15:28:50.003081 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb238221670>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2300b1940>, because it is not built.\n",
      "W0426 15:28:50.003232 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2300b1940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2300b1430>, because it is not built.\n",
      "W0426 15:28:50.003318 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2300b1430>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb2300b1a30>, because it is not built.\n",
      "W0426 15:28:50.003395 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb2300b1a30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2300b1e80>, because it is not built.\n",
      "W0426 15:28:50.003468 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2300b1e80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2302859d0>, because it is not built.\n",
      "W0426 15:28:50.003538 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2302859d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb230285700>, because it is not built.\n",
      "W0426 15:28:50.003607 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb230285700>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb230285970>, because it is not built.\n",
      "W0426 15:28:50.003677 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb230285970>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2302376a0>, because it is not built.\n",
      "W0426 15:28:50.003748 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2302376a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb2303560a0>, because it is not built.\n",
      "W0426 15:28:50.003817 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb2303560a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb23042d2e0>, because it is not built.\n",
      "W0426 15:28:50.003887 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb23042d2e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2300aa100>, because it is not built.\n",
      "W0426 15:28:50.003957 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2300aa100>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2382219a0>, because it is not built.\n",
      "W0426 15:28:50.004026 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2382219a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d4686d30>, because it is not built.\n",
      "W0426 15:28:50.004095 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d4686d30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d467ac10>, because it is not built.\n",
      "W0426 15:28:50.004163 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d467ac10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb23074c310>, because it is not built.\n",
      "W0426 15:28:50.004232 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb23074c310>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb230231ca0>, because it is not built.\n",
      "W0426 15:28:50.004300 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb230231ca0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb230231460>, because it is not built.\n",
      "W0426 15:28:50.004369 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb230231460>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2303d7520>, because it is not built.\n",
      "W0426 15:28:50.004445 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2303d7520>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2303d7fa0>, because it is not built.\n",
      "W0426 15:28:50.004514 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb2303d7fa0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2382219d0>, because it is not built.\n",
      "W0426 15:28:50.004583 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb2382219d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45f9940>, because it is not built.\n",
      "W0426 15:28:50.004652 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45f9940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45eff10>, because it is not built.\n",
      "W0426 15:28:50.004722 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45eff10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45ef340>, because it is not built.\n",
      "W0426 15:28:50.004790 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45ef340>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45ef880>, because it is not built.\n",
      "W0426 15:28:50.004859 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45ef880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45efd60>, because it is not built.\n",
      "W0426 15:28:50.004928 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45efd60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45ef5e0>, because it is not built.\n",
      "W0426 15:28:50.004997 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45ef5e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45ef160>, because it is not built.\n",
      "W0426 15:28:50.005065 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45ef160>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb238221a00>, because it is not built.\n",
      "W0426 15:28:50.005134 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb238221a00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45f4850>, because it is not built.\n",
      "W0426 15:28:50.005208 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45f4850>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d4601640>, because it is not built.\n",
      "W0426 15:28:50.005279 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d4601640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d4601d00>, because it is not built.\n",
      "W0426 15:28:50.005346 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d4601d00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d4601d30>, because it is not built.\n",
      "W0426 15:28:50.005414 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d4601d30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d46014f0>, because it is not built.\n",
      "W0426 15:28:50.005482 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d46014f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45fd790>, because it is not built.\n",
      "W0426 15:28:50.005550 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45fd790>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45fd250>, because it is not built.\n",
      "W0426 15:28:50.005621 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d45fd250>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45fd310>, because it is not built.\n",
      "W0426 15:28:50.005690 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d45fd310>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d460cbe0>, because it is not built.\n",
      "W0426 15:28:50.005759 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d460cbe0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d460cf10>, because it is not built.\n",
      "W0426 15:28:50.005827 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d460cf10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d460cfa0>, because it is not built.\n",
      "W0426 15:28:50.005895 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d460cfa0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d462a430>, because it is not built.\n",
      "W0426 15:28:50.005963 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d462a430>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d462a5e0>, because it is not built.\n",
      "W0426 15:28:50.006031 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d462a5e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d462a910>, because it is not built.\n",
      "W0426 15:28:50.006098 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb1d462a910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d462aac0>, because it is not built.\n",
      "W0426 15:28:50.006166 140405113897920 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fb1d462aac0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0426 15:29:05.424476 140405113897920 save.py:233] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: workspace/data/inference_graph/saved_model/assets\n",
      "I0426 15:29:10.353453 140405113897920 builder_impl.py:779] Assets written to: workspace/data/inference_graph/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to workspace/data/inference_graph/pipeline.config\n",
      "I0426 15:29:10.946638 140405113897920 config_util.py:253] Writing pipeline config file to workspace/data/inference_graph/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dfffc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 15:29:21.783447: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2400x1600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_name= 'image2.jpg'\n",
    "\n",
    "#Loading the saved_model\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "IMAGE_SIZE = (12, 8) # Output display size as you want\n",
    "import matplotlib.pyplot as plt\n",
    "PATH_TO_SAVED_MODEL=os.path.join(paths['DATA_PATH'],'inference_graph','saved_model')\n",
    "print('Loading model...', end='')\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "print('Done!')\n",
    "\n",
    "#Loading the label_map\n",
    "category_index=label_map_util.create_category_index_from_labelmap(files['LABEL_MAP'],use_display_name=True)\n",
    "#category_index=label_map_util.create_category_index_from_labelmap([path_to_label_map],use_display_name=True)\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "image_path = os.path.join(paths['DATA_PATH'],'test_images',image_name)\n",
    "#print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "input_tensor = tf.convert_to_tensor(image_np)\n",
    "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "# All outputs are batches tensors.\n",
    "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "# We're only interested in the first num_detections.\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_detections,\n",
    "      detections['detection_boxes'],\n",
    "      detections['detection_classes'],\n",
    "      detections['detection_scores'],\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=1,\n",
    "      min_score_thresh=.4, # Adjust this value to set the minimum probability boxes to be classified as True\n",
    "      agnostic_mode=False)\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=IMAGE_SIZE, dpi=200)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image_np_with_detections)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "033231ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-43e2894957df0458\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-43e2894957df0458\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {paths['TRAINING_PATH']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fad139",
   "metadata": {},
   "source": [
    "# Convercion a TFLite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357dc3e2",
   "metadata": {},
   "source": [
    "The output folder will contain an intermediate SavedModel that can be used with the TfLite converter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4d85730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python Tensorflow/models/research/object_detection/export_tflite_graph_tf2.py -pipeline_config_path workspace/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --trained_checkpoint_dir workspace/training --output_directory workspace/data/tflite'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"python {} -pipeline_config_path {} --trained_checkpoint_dir {} --output_directory {}\".format(os.path.join(paths['MODELS_PATH'],'research','object_detection','export_tflite_graph_tf2.py'),files['MODEL_CONFIG'],paths['TRAINING_PATH'],os.path.join(paths['DATA_PATH'],'tflite'))\n",
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0dad226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-26 15:29:29.011656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:29.016003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:29.016223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:29.020212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-26 15:29:29.021161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:29.021459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:29.021641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:29.422569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:29.422814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:29.423020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:29.423189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 95 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-04-26 15:29:34.762020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:34.762310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:34.762536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:34.762760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:34.762953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:34.763153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 95 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-04-26 15:29:34.777915: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-04-26 15:29:36.417588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:36.417903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:36.418130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:36.418391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:36.418616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:36.418792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 95 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-04-26 15:29:38.702453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:38.702786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:38.703043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:38.703328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:38.703568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:29:38.703757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 95 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fe2b80ba1c0>, because it is not built.\n",
      "W0426 15:29:38.998039 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fe2b80ba1c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe2b80baf70>, because it is not built.\n",
      "W0426 15:29:39.257615 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe2b80baf70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0140280>, because it is not built.\n",
      "W0426 15:29:39.257769 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0140280>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b01389d0>, because it is not built.\n",
      "W0426 15:29:39.257860 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b01389d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe2b037e940>, because it is not built.\n",
      "W0426 15:29:39.257941 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe2b037e940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b054f580>, because it is not built.\n",
      "W0426 15:29:39.258030 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b054f580>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b054f8b0>, because it is not built.\n",
      "W0426 15:29:39.258100 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b054f8b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe2545f0130>, because it is not built.\n",
      "W0426 15:29:39.258167 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe2545f0130>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2545f00a0>, because it is not built.\n",
      "W0426 15:29:39.258234 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2545f00a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2545f0190>, because it is not built.\n",
      "W0426 15:29:39.258301 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2545f0190>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe2b033e220>, because it is not built.\n",
      "W0426 15:29:39.258368 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe2b033e220>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2543c05e0>, because it is not built.\n",
      "W0426 15:29:39.258435 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2543c05e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2543c08b0>, because it is not built.\n",
      "W0426 15:29:39.258500 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2543c08b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b05975e0>, because it is not built.\n",
      "W0426 15:29:39.258566 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b05975e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b0373400>, because it is not built.\n",
      "W0426 15:29:39.258632 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b0373400>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b047dc70>, because it is not built.\n",
      "W0426 15:29:39.258697 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b047dc70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b047d910>, because it is not built.\n",
      "W0426 15:29:39.258763 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b047d910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b03b35b0>, because it is not built.\n",
      "W0426 15:29:39.258829 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b03b35b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b03b3a60>, because it is not built.\n",
      "W0426 15:29:39.258895 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b03b3a60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0190df0>, because it is not built.\n",
      "W0426 15:29:39.258962 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0190df0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b0190f10>, because it is not built.\n",
      "W0426 15:29:39.259037 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b0190f10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0597610>, because it is not built.\n",
      "W0426 15:29:39.259103 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0597610>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b01e47c0>, because it is not built.\n",
      "W0426 15:29:39.259169 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b01e47c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b03524c0>, because it is not built.\n",
      "W0426 15:29:39.259235 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b03524c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b0352040>, because it is not built.\n",
      "W0426 15:29:39.259304 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b0352040>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b01d34f0>, because it is not built.\n",
      "W0426 15:29:39.259372 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b01d34f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b01d3a60>, because it is not built.\n",
      "W0426 15:29:39.259439 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b01d3a60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0434a60>, because it is not built.\n",
      "W0426 15:29:39.259505 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0434a60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b04341c0>, because it is not built.\n",
      "W0426 15:29:39.259572 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b04341c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0597640>, because it is not built.\n",
      "W0426 15:29:39.259638 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0597640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b03f99d0>, because it is not built.\n",
      "W0426 15:29:39.259704 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b03f99d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0368d30>, because it is not built.\n",
      "W0426 15:29:39.259769 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b0368d30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b02ae7c0>, because it is not built.\n",
      "W0426 15:29:39.259834 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b02ae7c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b040a9a0>, because it is not built.\n",
      "W0426 15:29:39.259901 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b040a9a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b040ad00>, because it is not built.\n",
      "W0426 15:29:39.259966 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b040ad00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b014a610>, because it is not built.\n",
      "W0426 15:29:39.260031 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b014a610>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b014aa60>, because it is not built.\n",
      "W0426 15:29:39.260100 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b014aa60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b054c130>, because it is not built.\n",
      "W0426 15:29:39.260166 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b054c130>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b054c790>, because it is not built.\n",
      "W0426 15:29:39.260232 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b054c790>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b01869d0>, because it is not built.\n",
      "W0426 15:29:39.260299 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b01869d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b0186670>, because it is not built.\n",
      "W0426 15:29:39.260370 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b0186670>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe254632af0>, because it is not built.\n",
      "W0426 15:29:39.260437 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe254632af0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2546329d0>, because it is not built.\n",
      "W0426 15:29:39.260503 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2546329d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b05345e0>, because it is not built.\n",
      "W0426 15:29:39.260570 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe2b05345e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b05343a0>, because it is not built.\n",
      "W0426 15:29:39.260689 140613373469632 save_impl.py:62] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe2b05343a0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0426 15:29:53.359003 140613373469632 save.py:233] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: workspace/data/tflite/saved_model/assets\n",
      "I0426 15:29:57.503239 140613373469632 builder_impl.py:779] Assets written to: workspace/data/tflite/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9eb0ef",
   "metadata": {},
   "source": [
    "GRAPH DEL MODELO ENTRENADO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4c596db",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"saved_model_cli show --dir {} --tag_set serve --all\".format(os.path.join(paths['DATA_PATH'],'tflite','saved_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b043ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (1, 320, 320, 3)\n",
      "        name: serving_default_input:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_0'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: ()\n",
      "        name: StatefulPartitionedCall:0\n",
      "    outputs['output_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: ()\n",
      "        name: StatefulPartitionedCall:1\n",
      "    outputs['output_2'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: ()\n",
      "        name: StatefulPartitionedCall:2\n",
      "    outputs['output_3'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: ()\n",
      "        name: StatefulPartitionedCall:3\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Concrete Functions:\n",
      "  Function Name: 'inference_fn'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input: TensorSpec(shape=(1, 320, 320, 3), dtype=tf.float32, name='input')\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc51a51",
   "metadata": {},
   "source": [
    "El conversor de TensorFlow Lite toma un modelo de TensorFlow y genera un modelo de TensorFlow Lite .tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c69a354d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tflite_convert --saved_model_dir=workspace/data/tflite/saved_model --output_file=workspace/data/tflite/detect.tflite'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"tflite_convert --saved_model_dir={} --output_file={}\".format(os.path.join(paths['DATA_PATH'],'tflite','saved_model'),os.path.join(paths['DATA_PATH'],'tflite','detect.tflite'))\n",
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0707d460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-26 15:30:11.219353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:30:11.223612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:30:11.223865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:30:11.655087: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-26 15:30:11.655888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:30:11.656186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:30:11.656418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:30:12.155003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:30:12.155272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:30:12.155490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:30:12.155679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1549] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 99 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-04-26 15:30:20.801250: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-04-26 15:30:20.801274: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-04-26 15:30:20.801845: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: workspace/data/tflite/saved_model\n",
      "2022-04-26 15:30:20.854026: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2022-04-26 15:30:20.854060: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: workspace/data/tflite/saved_model\n",
      "2022-04-26 15:30:20.990888: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-04-26 15:30:21.029875: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-04-26 15:30:21.693863: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: workspace/data/tflite/saved_model\n",
      "2022-04-26 15:30:22.024233: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1222389 microseconds.\n",
      "2022-04-26 15:30:22.560191: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-04-26 15:30:23.221298: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1972] Estimated count of arithmetic ops: 1.706 G  ops, equivalently 0.853 G  MACs\n",
      "\n",
      "Estimated count of arithmetic ops: 1.706 G  ops, equivalently 0.853 G  MACs\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cac2a",
   "metadata": {},
   "source": [
    "Las ultimas versiones de TFLite requieren el agregado de la siguiente metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddb9c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q tflite-model-maker\n",
    "#!pip install -q tflite-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b0f6ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata populated:\n",
      "{\n",
      "  \"name\": \"ObjectDetector\",\n",
      "  \"description\": \"Identify which of a known set of objects might be present and provide information about their positions within the given image or a video stream.\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"image\",\n",
      "          \"description\": \"Input image to be detected.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"ImageProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"color_space\": \"RGB\"\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"NormalizationOptions\",\n",
      "              \"options\": {\n",
      "                \"mean\": [\n",
      "                  127.5\n",
      "                ],\n",
      "                \"std\": [\n",
      "                  127.5\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              -1.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"score\",\n",
      "          \"description\": \"The scores of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            },\n",
      "            \"range\": {\n",
      "              \"min\": 2,\n",
      "              \"max\": 2\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"location\",\n",
      "          \"description\": \"The locations of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"BoundingBoxProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"index\": [\n",
      "                1,\n",
      "                0,\n",
      "                3,\n",
      "                2\n",
      "              ],\n",
      "              \"type\": \"BOUNDARIES\"\n",
      "            },\n",
      "            \"range\": {\n",
      "              \"min\": 2,\n",
      "              \"max\": 2\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"number of detections\",\n",
      "          \"description\": \"The number of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"category\",\n",
      "          \"description\": \"The categories of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            },\n",
      "            \"range\": {\n",
      "              \"min\": 2,\n",
      "              \"max\": 2\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          },\n",
      "          \"associated_files\": [\n",
      "            {\n",
      "              \"name\": \"labelmap.txt\",\n",
      "              \"description\": \"Labels for categories that the model can recognize.\",\n",
      "              \"type\": \"TENSOR_VALUE_LABELS\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_groups\": [\n",
      "        {\n",
      "          \"name\": \"detection_result\",\n",
      "          \"tensor_names\": [\n",
      "            \"location\",\n",
      "            \"category\",\n",
      "            \"score\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"min_parser_version\": \"1.2.0\"\n",
      "}\n",
      "\n",
      "Associated file(s) populated:\n",
      "['labelmap.txt']\n"
     ]
    }
   ],
   "source": [
    "#Tomado de https://github.com/techzizou\n",
    "!mkdir -p os.path.join('workspace','data','tflite','tflite_with_metadata')\n",
    "import tflite_support\n",
    "from tflite_support.metadata_writers import object_detector\n",
    "from tflite_support.metadata_writers import writer_utils\n",
    "from tflite_support import metadata\n",
    "import flatbuffers\n",
    "import os\n",
    "from tensorflow_lite_support.metadata import metadata_schema_py_generated as _metadata_fb\n",
    "from tensorflow_lite_support.metadata.python import metadata as _metadata\n",
    "from tensorflow_lite_support.metadata.python.metadata_writers import metadata_info\n",
    "from tensorflow_lite_support.metadata.python.metadata_writers import metadata_writer\n",
    "from tensorflow_lite_support.metadata.python.metadata_writers import writer_utils\n",
    "\n",
    "ObjectDetectorWriter = object_detector.MetadataWriter\n",
    "\n",
    "_MODEL_PATH = os.path.join(paths['DATA_PATH'],'tflite','detect.tflite')\n",
    "_LABEL_FILE = os.path.join(paths['DATA_PATH'],'labelmap.txt')\n",
    "_SAVE_TO_PATH = os.path.join(paths['DATA_PATH'],'tflite','tflite_with_metadata','detect.tflite')\n",
    "\n",
    "writer = ObjectDetectorWriter.create_for_inference(\n",
    "    writer_utils.load_file(_MODEL_PATH), [127.5], [127.5], [_LABEL_FILE])\n",
    "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)\n",
    "\n",
    "# Verify the populated metadata and associated files.\n",
    "displayer = metadata.MetadataDisplayer.with_model_file(_SAVE_TO_PATH)\n",
    "print(\"Metadata populated:\")\n",
    "print(displayer.get_metadata_json())\n",
    "print(\"Associated file(s) populated:\")\n",
    "print(displayer.get_packed_associated_file_list())\n",
    "\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = \"SSD_Detector\"\n",
    "model_meta.description = (\n",
    "    \"Identify which of a known set of objects might be present and provide \"\n",
    "    \"information about their positions within the given image or a video \"\n",
    "    \"stream.\")\n",
    "\n",
    "# Creates input info.\n",
    "input_meta = _metadata_fb.TensorMetadataT()\n",
    "input_meta.name = \"image\"\n",
    "input_meta.content = _metadata_fb.ContentT()\n",
    "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
    "input_meta.content.contentProperties.colorSpace = (\n",
    "    _metadata_fb.ColorSpaceType.RGB)\n",
    "input_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.ImageProperties)\n",
    "input_normalization = _metadata_fb.ProcessUnitT()\n",
    "input_normalization.optionsType = (\n",
    "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
    "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
    "input_normalization.options.mean = [127.5]\n",
    "input_normalization.options.std = [127.5]\n",
    "input_meta.processUnits = [input_normalization]\n",
    "input_stats = _metadata_fb.StatsT()\n",
    "input_stats.max = [255]\n",
    "input_stats.min = [0]\n",
    "input_meta.stats = input_stats\n",
    "\n",
    "# Creates outputs info.\n",
    "output_location_meta = _metadata_fb.TensorMetadataT()\n",
    "output_location_meta.name = \"location\"\n",
    "output_location_meta.description = \"The locations of the detected boxes.\"\n",
    "output_location_meta.content = _metadata_fb.ContentT()\n",
    "output_location_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.BoundingBoxProperties)\n",
    "output_location_meta.content.contentProperties = (\n",
    "    _metadata_fb.BoundingBoxPropertiesT())\n",
    "output_location_meta.content.contentProperties.index = [1, 0, 3, 2]\n",
    "output_location_meta.content.contentProperties.type = (\n",
    "    _metadata_fb.BoundingBoxType.BOUNDARIES)\n",
    "output_location_meta.content.contentProperties.coordinateType = (\n",
    "    _metadata_fb.CoordinateType.RATIO)\n",
    "output_location_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_location_meta.content.range.min = 2\n",
    "output_location_meta.content.range.max = 2\n",
    "\n",
    "output_class_meta = _metadata_fb.TensorMetadataT()\n",
    "output_class_meta.name = \"category\"\n",
    "output_class_meta.description = \"The categories of the detected boxes.\"\n",
    "output_class_meta.content = _metadata_fb.ContentT()\n",
    "output_class_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_class_meta.content.contentProperties = (\n",
    "    _metadata_fb.FeaturePropertiesT())\n",
    "output_class_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_class_meta.content.range.min = 2\n",
    "output_class_meta.content.range.max = 2\n",
    "label_file = _metadata_fb.AssociatedFileT()\n",
    "label_file.name = os.path.basename(\"labelmap.txt\")\n",
    "label_file.description = \"Label of objects that this model can recognize.\"\n",
    "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_VALUE_LABELS\n",
    "output_class_meta.associatedFiles = [label_file]\n",
    "\n",
    "output_score_meta = _metadata_fb.TensorMetadataT()\n",
    "output_score_meta.name = \"score\"\n",
    "output_score_meta.description = \"The scores of the detected boxes.\"\n",
    "output_score_meta.content = _metadata_fb.ContentT()\n",
    "output_score_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_score_meta.content.contentProperties = (\n",
    "    _metadata_fb.FeaturePropertiesT())\n",
    "output_score_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_score_meta.content.range.min = 2\n",
    "output_score_meta.content.range.max = 2\n",
    "\n",
    "output_number_meta = _metadata_fb.TensorMetadataT()\n",
    "output_number_meta.name = \"number of detections\"\n",
    "output_number_meta.description = \"The number of the detected boxes.\"\n",
    "output_number_meta.content = _metadata_fb.ContentT()\n",
    "output_number_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_number_meta.content.contentProperties = (\n",
    "    _metadata_fb.FeaturePropertiesT())\n",
    "\n",
    "# Creates subgraph info.\n",
    "group = _metadata_fb.TensorGroupT()\n",
    "group.name = \"detection result\"\n",
    "group.tensorNames = [\n",
    "    output_location_meta.name, output_class_meta.name,\n",
    "    output_score_meta.name\n",
    "]\n",
    "subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "subgraph.inputTensorMetadata = [input_meta]\n",
    "subgraph.outputTensorMetadata = [\n",
    "    output_location_meta, output_class_meta, output_score_meta,\n",
    "    output_number_meta\n",
    "]\n",
    "subgraph.outputTensorGroups = [group]\n",
    "model_meta.subgraphMetadata = [subgraph]\n",
    "\n",
    "b = flatbuffers.Builder(0)\n",
    "b.Finish(\n",
    "    model_meta.Pack(b),\n",
    "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
    "metadata_buf = b.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c506518b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
